JavaScript Algorithms and Data Structures Masterclass Notes

Big O.   “tell me the big O of this function” is a common interview question.

Example: write function that calculates sum from 1 to n
VERSION 1
function addUpTo(n) {
    let total = 0;
    for (let i = 1; i<=n; i++) {
        total += i;
    }
    return total;
}

console.log("your total is", addUpTo(6))
VERSION 2
//single line, same problem as previous but without loop.  This uses a mathematical formula rather than looping.
function addUpTo(n) {
    return n * (n + 1) / 2;
}

console.log("quickly!  sum is", addUpTo(6));

The Problem With Time
1)	Different machines will record different times (due to processor speed, configurations etc)
2)	The SAME MACHINE will record different times (depending on other processes running)
3)	For fast algorithms, this measurement may not be precise enough

Lets try counting number of simple operations.
Fast version has totally only 3 operations: one multiplication, one addition, one division.
Slow version has: 2 operations per increment of index variable in for loop (addition and assignment) also, 2 per increment of total.  Also, comparisons, initial variable assignment…..  Therefore, complexity  is like 5n+2.  But, lets just say, grows proportionally with n.

This means big o is linear.


BIG O is formalized fuzzy counting.  Formally describing relationship between input size and runtime.  No details just trends.  Scalability.
O(f(n)) : number of simple operations is eventually less than a constant times f(n) as n increases.

Linear f(n) = n, quadratic f(n) = n^2, constant f(n) = 1 or something else
Big o should represent worst case, upper bound of runtime.

SO:  our fast add example is O(1) and slower is O(n)

If we nest a loop within a loop we will get O(n^2)

Shorthands: arithmetic operations, variable assignment, accessing elements in an indexed array or hash is constant
In a loop the complexity is the length of the loop.

Logarithmic time complexity is more common with searching and sorting algorithms, and log space complexity can come up with recursive algorithms.

Space Complexity

You can still use big o notation, but this has to do with memory used not with time.
(auxilery space complexity: the algorithm only, not the inputs)
Primmitives are constant space (Booleans, numbers, undefined, null)

Strings require O(n) space, where n is length of string (number of characters)
Reference types are also generally O(n): the length of the array or the number of key/value pairs


JavaScript Objects!
Unordered key value pairs (hash)
Let instructor = {
	firstName: “Kelly”,
	isInstructor: true,
	favoriteNumbers: [1,2,3,4]
}

Fast access and insertion, order isn’t relevant.

Insertion, removal, and access are all O(1), searching is O(n)
Methods of javascript objects: Object.keys(the object)

Arrays
When to use array?  Well, when you need order.  Also theyre built in.
Insertion and removal, complexity depends on if you are pushing, or if you are having to reindex everything by adding to front or middle of list.
Searching O(n)
Accessing: O(1)
Push and pop are O(1) but all other built in methods are O(n) except sort

How do you improve on solving problems
1)	Devise a plan
2)	Master common patterns

Steps
-	Understand the problem
Ask questions! Either to yourself or interviewer.  1) can I restate the problem in my own words?
							2) what are the inputs that go into the problem?
							3) how about the outputs from the solution, and what do they look like?
							4) can outputs be determined from inputs?  Do I have enough info to solve the problem?
							5) how should I label the important pieces of data? (what are the things that really matter and what is the terminology I should use?)

Example: write a function that takes 2 numbers and returns their sum.
1)	Can I restate the problem in my own words?  Sure.  Implement addition.  Write a function that adds two numbers.
2)	What are the inputs that go into the problem?  (integers? Floating points? How large are the numbers going to be (upper bounds)?  Are we only working with two inputs?  What if one is left off, or we get more than 2 inputs?
3)	What should the output look like?  Similar questions, should it be integer? Float? String?
4)	Can the outputs be determined from the inputs?  Potentially, but what do we output if inputs aren’t the right numbers etc.
5)	How should I label the important pieces of data?  Name the function add, num1 and num2 arguments, sum is result.

-	Explore concrete examples
Coming up with examples can help you understand the problem better.  Also provides sanity checks, make sure solution works the way it should.  User Stories!

Start with SIMPLE examples.  Write down two or three, with the input and the output.  Actually physically write it down.
Progress to more complex examples and edge cases
Explore examples with empty inputs
Explore examples with invalid inputs

	Example: write a function which takes in a string and returns counts of each character in the string.

charCount(“aaaa”); //{a:4}
charCount(“hello”); // {h:1, 3:1, l:2, o:1}
those are simple examples.  What about strings that include numbers?  Uppercase vs lowercase?  “my number is 55521234” “Hello hi”

what if empty string? Or completely empty input?  Or something that isn’t a string at all?  What do we want to return?

These edge cases may not be as important for interview but will be important for real world problem solving.



-	Break it down
This could just be pseudocode.  Do them as comments?  You could even throw in a “does that sound crazy to you?”  explicitly write out the steps you will need to take.  Basic components of solution.  This forces you to think about the code before you write it, and will catch any lingering conceptual issues or misundrestandings.

Function charCount(str){
// make object to return at end
var result = {};
// loop over string
	For(var I = 0;
	// for each character, if char is a number/letter and already key in object, increment.  If alphanum and not in object, add and set value to 1.  If not alphanum do nothing.
// return object at end
// return an object with keys that are lowercase alphanumeric characters and values that are count of the times they appeared.


-	Solve/simplify
Solve the problem if you can, but if not, solve a simpler problem!  Break it down into the pieces you do know how to do.  Why is this worthwhile?  In an interview setting you want to have SOMEHTING to show for yourself, so rather than getting stuck and making zero progress, start writing code and demonstrating the stuff you know how to do.  Also, in simplifying the problem, you will often gain insight into how to solve the bigger problem.  Go for it!

Find the core difficutly
Ignore it
Write simplified solution
Incorporate difficulty back in.


-	Look back and refactor
Most important step in terms of improving and becoming a better developer
Just because you have a good enough workable solution, don’t fall into temptation to stop there!  That might get by (including in a lot of jobs), but wouldn’t you rather strive for more beautiful, efficient code?  Missed opportunity not to look back and reflect
Some questions you can ask:
	Can you check the result?
	Can you derive the result differently? (rarely only one solution to a problem)
	Can you understand it at a glance? (how intuitive is your solution?)
	Can you use the result, or the method, for some other problem?  (are there similarities to other problems you have encountered?)
	Can you improve the performance of your solution? (big o time or space complexity)
	Can you think of other ways to refactor?  (do you follow the style guide/conventions?  Acknowledge if your code isn’t neat)
	How have other people solved this problem?  (often interview questions get recycled.  Pick their brain!  Ask what other solutions have been attempted or whether you missed anything!  You can learn a lot from this, whether or not you get the job.  Also, don’t need to reinvent the wheel when working on your own projects)



Mastering Common Problem-Solving Patterns
These are blueprints for implementing common solutions

Frequency counter pattern:
	Uses objects or sets to collect values/frequency of values.  This can often avoid the need for nested loops when working on arrays or strings

Example: write a function called “same” which accepts two arrays.  Should return true if every value in the second array has its corresponding value squared in the second array.  The frequency of values must be the same (if a value appears once, only one copy of its square)

Naïve approach:
Compare length of arrays, return false if not equal
Iterate thru first array, taking each value.  Square the value and look for it in the second array.  Remove the square from the second array.  If at any point during that comparison the result is false, return false.  Otherwise if you get all the way thru the array and its always true, return true.

But this is a nested loop approach!
Lets try frequency counter approach.  Loop over each array 1 time individually.  2 loops is vastly better than nested loops.
So, frequency counter converts each array into an object (hash) where keys are numbers and values are frequency that number appears.
It does this by: for of loop, with each array element, key into object (remember, numbers in array are keys in object) and assign a new value using a || (or) statement like so:
obj[val] = (obj[val] || 0) + 1
that way if it already exists it will add 1, and if it does not it will add 1 to zero, resulting in 1
after going through each array, compare the two objects, one at a time.

Multiple Pointers Pattern:
This works best with ordered arrays/sorted lists.  Imagine we want to find two values that add up to zero.  We could do a nested loop, comparing one item at a time to every other.

Rather than a nested loop, we have one pointer point at smallest value (index 0) and the other at largest (index = length - 1).  Compare those (in this case, add them).  If a positive result, decrement high index.  If negative, increment low index.  If zero, you win! Return those values.

Could also use for countUniqueValues.  This fn accepts a sorted array and counts the unique values.

Sliding Window Pattern:
Useful when you have a string or array and you want to find a continuous subset from that data.  Such as, longest substring of unique chars, or max sum sub array from larger array (of continuous values).
You could do nested loops, where first loop looks at one element at a time, and then second loop adds (or checks uniqueness) for each element after, stores the final solution based on that starting point and then moves on to the next.
Above is O(N^2).

But sliding window is better, because it means we don’t have to re-check or re-add quite so many times! O(n)
So, add or check the length you want, then move the window by removing the first value and adding the one that follows your last value in your prior sub-array or sub-string.

Divide and Conquer:
Take larger set of data and rather than starting from left and moving to right, start by dividing into smaller pieces and doing something to each smaller piece to determine where to go next
Depending on the problem this can be a significant helper.
Binary search is an example of this.
Linear search is O(n), binary is O(log n)





RECURSION

generally, most problems can either be solved by recursion or iteration

objectives:
•	define recursion
•	explicitly identify two essential components
•	visualize call stack
•	use helper methods AND pure recursion.

Function that calls itself
Can be cleaner than iteration.

Call Stack
FILO/LIFO
Invoke, push onto call stack
Return, pop off of call stack
With recursion, we keep pushing the same function onto the call stack without returning until we reach our base case

Factorial!

Common pitfalls:
Forget to include base case (causes recursion loop stack overflow)
Forget to return, or return wrong thing

Helper methods
Helper method is recursive and invoked within some other function.  This way you can initialize variables without overwriting them during recursion.

Pure Recursion
Rather than helper methods, this involves creating a new array and including it in your recursive invocation.  Example:
new = new.concat(recursiveFunction(old.slice(1)));
return new;


Search
Linear search
Just like it sounds, loop through all contents until you either find the item you are searching for or you reach the end.
Javascript has built-in linear search methods: indexOf, includes, find, findIndex

Pseudocode linear search (accepts an array and a value)
Loop thru array and check if current element is equal to value
If it is return index
If not, return -1

Binary Search
Only works on sorted data.  Cut in half each time you search (similar to “higher/lower” game).
Take middle element and determine if value you search for is before or after
“divide and conquer”.  Pivot Point.

Pseudocode binary search
Accept a sorted array and a value
Create a left pointer variable and a right pointer variable (index variables)
Loop while left is less than right
Create pointer in middle
If that’s the value you want, return the index
If its too small, left = center
If too big, right = center
Pick a new middle
If after loop value is not found, return not found (-1)

Time complexity is significantly less.  Worst and average case are both O(log n) and best case is O(1)

“naïve” string search
Imagine you want to count the number of times a smaller string appears in a larger string.

Pseudocode:
Accept a long string and a short string
Loop over the longer string
Loop over short string
If characters don’t match, break out of inner loop
If they do match, move on to next character until you hit end of short string.
If you hit end of short string, you have a match: increment count of matches
At the end of long string, return the count.

In order to reduce time complexity, this is when you would implement Knuth-Morris-Pratt algorithm (KMP)

Pseudocode kmp
Make array to track prefix/suffix patterns in short string
(two index variables on short string (I and j).  Increase i and add values to pattern array each time.  If value at j matches value at i, then value should be j+1 and both j and I should be increased.  If they do not match, j = patternArray[j-1], while I remains the same. )
Once pattern array length is the same as short string length, move on to actual search
Compare long string to short string, starting at index zero
If they are same, check if short string index is at the end (in which case increment return value counter), then increment both pointers
Else, if short index is greater than zero, keep long string index the same, short pointer = array[short pointer-1] or zero, just like when you built the array
if short pointer is zero and they don’t match (this is just an “else” situation) increase text pointer
Once you reach the end of the long string, you are finished and can return the count variable.



Elementary Sorting Algorithms

Sorting is considered the quintessential CS challenge
Generally, this is rearranging the items in a collection (such as an array) so theyre in some kind of order.
Things you could sort by:
•	small to large
•	alphabetically
•	date

simple challenge, but lots of different ways to do it.  There are lots of well known and named searching algorithms.  Some are pretty robust and are good for many use cases.  Some are more “niche” and might be bad at certain types of data but great at others.  Each have their own advantages and disadvantages.

JS Built In Array.sort method
Works for alphabetical but not for numbers.  Uses string Unicode code points.
You can pass in how to sort as an argument and that will help.
Accepts optional comparator function

Comparator looks at pairs of elements and determines sort order based on return value
If it returns a negative number, then A comes before B, if positive a after b, if 0 they are equivalent value

For example: function numberCompare(num1, num2){
Return num1 – num2
}

Then if you pass that function in to the sort, it will sort them numerically small to large

Bubble Sort
Not very efficient or commonly used, really only has one or two use cases where it excels
Its fun and there are optimizations you can make.  Helps you understand how other sort algorithms are better
Compare 2 adjacent and swap if those two aren’t in prescribed order
Go thru the list over and over until you can make it thru without a single swap

Swapping: how does it work?
Tried and true, more legible:
Function swap(arr, idx1, idx2){
	Var temp = arr[idx1];
	Arr[idx1 = arr[idx2];
Arr[idx2] = temp

Fancier, inline version:
Const swap = (arr, idx1, idx2) => { [arr[idx1], arr[idx2]] = [arr[idx2], arr[idx1]]; }

Bubble sort pseudocode
Start looping with a variable called I at the end of the array towards the beginning
Start an inner loop with a variable called j, going from the beginning until i-1
If arr[j] > arr[j+1], swap the two values
Return sorted array


Selection Sort
Similar to bubble sort but instead of swapping each pair, you only swap after comparing all.  What does this mean?
Set a temp minimum as you iterate through, then swap the min with the first value.  0th is now set and you can move to next index and so on.
(you could also go the other direction and seek the max, doesn’t really matter)

Pseudo code:
Reuse swap functionality from bubble sort, same logic.
Loop over the array and on each loop, smallest seen so far starts as first index
Compare to next and next and next until you find smaller (nested loop)
If smaller found, make note of the index of smaller value
Once you get to the end, swap min with first index and do it again with the next index and the next until you reach the end of the list and its all sorted
Return the sorted array

Insertion sort
Builds up the sort by gradually creating a larger half of the array which is always sorted
Instead of finding largest or smallest, takes each element and places it where it should go in the sorted half

Pseudocode:
Start with second element of array
Compare to the one before and swap if necessary
Continue to next element, if it’s in the incorrect order, iterate through sorted portion (left side) and place it in the correct spot
Repeat until sorted

Big O worst case, insertion is quadratic O(n^2).  But if almost all sorted, gets much closer to linear (O(n))

Online algorithm: can work with live data being added in, can sort each new piece of data as it comes in.  doesn’t matter what item comes in, your logic can place it where it needs to go.

Comparing bubble, selection and insertion
best time, average time, worst time, space
bubble      O(n)            O(n^2)          O(n^2)          O(1)
insert      O(n)            O(n^2)          O(n^2)          O(1)
select      O(n^2)          O(n^2)          O(n^2)          O(1)


Intermediate sorting algorithms
Implementing merge sort, quick sort and radix sort
These can get as low as O(n log n) in times the others would be quadratic
These are more complex algorithms.  Not intuitive for human thought patterns


Merge sort
Splitting, Merging and Sorting
Exploits the fact that an array of 1 element (or zero) is already sorted.
Decomposes an array into smaller arrays (divide and conquer) with zero or one elements

Merging two sorted arrays
Input is two sorted arrays, function should create new sorted array consisting of all elements in the input arrays
Should run O(n+m) time and space and should not modify the arrays that are passed in

PSEUDOCODE
Create empty array for return later, start with smallest values in each input array, two counters
While counters are less than lengths
	If the value in the first array is smaller than the value in the second, push the value in the first into the results and then increment counter
	If larger, push second array val and inc that count
	Once one array is done, push all from other

Break the array into halves until you have arrays that are empty or have one element.
Use slice: from zero to middle of array, from middle to zero.
Do this recursively, when length <=1 is base case
Once have smaller arrays, merge back until fully sorted and return

Big O
In all cases, time complexity is O(n log n).  space is O(n).
Why n log n?
Because splitting step is log!  It’s a powers of two type thing.  Merging is n because you have to merge all the things individually but splitting will only happen log(n).  num of splits^2 = the original number being split



Quick Sort
Like merge, also exploits fact that arrays of 1 or less length are inherently sorted.

Works by selecting one element (the pivot) and finding the index where the pivot should end up in the sorted array
Once pivot is positioned appropriately, quick sort can be applied on either side of pivot.

Pivot Helper
given array, designate one element as the pivot
rearrange elements in the array so that all values less than the pivot are moved to the left, then all values greater are to the right
order of elements doesn’t matter, just relationship to pivot
do this in place, rather than making new array
return index of pivot

picking a pivot is an important decision
ideally should be median value in data set
for simplicity, to start, we will make first element be pivot

pseudocode
accepts three arguments: array, startidx, endidx (default should be 0 and length-1)
grab pivot from start of array
store in variable
loop thru array
if pivot is greater than current element, increment pivot index variable and swap current element with element at pivot index
swap starting element (i.e. pivot) with pivot index
return pivot index

call pivot helper on full array
recursively call it to left and right of pivot


NOTE that this approach modifies the array in place.  Merge sort approach didn’t actually modify original array, just returned a new sorted array (though this could easily be changed with one line of code)
Best case O(n log n), worst case O(n^2)
